{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbde311-5125-4a65-95e4-cc464bf20731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (0.12.3)\n",
      "Requirement already satisfied: xgboost in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\vetdd\\anaconda3\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn xgboost\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import (\n",
    "    precision_score, f1_score, make_scorer,\n",
    "    precision_recall_curve, average_precision_score,\n",
    "    brier_score_loss, confusion_matrix, ConfusionMatrixDisplay, accuracy_score,\n",
    "    matthews_corrcoef\n",
    ")\n",
    "from sklearn.calibration import calibration_curve\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Load & split data\n",
    "df = pd.read_csv(\"data/bcsc_concatenated_no_9_2.csv\")\n",
    "X = df.drop(columns=\"breast_cancer_history\")\n",
    "y = df[\"breast_cancer_history\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# estimate imbalance ratio for prop in grid\n",
    "scale_pos_weight = len(y_train[y_train==0]) / len(y_train[y_train==1])\n",
    "\n",
    "# Build an imblearn Pipeline with SMOTE + XGBClassifier \n",
    "pipeline = Pipeline([\n",
    "    (\"smote\", SMOTE(random_state=42)),\n",
    "    (\n",
    "      \"clf\",\n",
    "      xgb.XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"aucpr\",\n",
    "        use_label_encoder=False,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "      )\n",
    "    )\n",
    "])\n",
    "\n",
    "# Hyperparameter grid \n",
    "param_dist = {\n",
    "    \"clf__n_estimators\":     [100, 300, 500, 800],\n",
    "    \"clf__max_depth\":        [3, 5, 7],\n",
    "    \"clf__learning_rate\":    [0.01, 0.05, 0.1],\n",
    "    \"clf__subsample\":        [0.6, 0.8, 1.0],\n",
    "    \"clf__colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "    \"clf__gamma\":            [0, 1, 5],\n",
    "    \"clf__reg_alpha\":        [0, 0.1, 1, 5],\n",
    "    \"clf__reg_lambda\":       [0.1, 1, 5, 10],\n",
    "    \"clf__scale_pos_weight\": [1.0, scale_pos_weight, scale_pos_weight*2, scale_pos_weight*5]\n",
    "}\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    scoring=make_scorer(f1_score, pos_label=1),\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best hyperparameters:\", search.best_params_)\n",
    "\n",
    "# Retrain on full training set \n",
    "best_pipeline = search.best_estimator_\n",
    "best_clf = best_pipeline.named_steps[\"clf\"]\n",
    "best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities on test set & compute PR data \n",
    "y_prob = best_pipeline.predict_proba(X_test)[:, 1]\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_prob)\n",
    "avg_prec = average_precision_score(y_test, y_prob)\n",
    "\n",
    "# Threshold selection \n",
    "\n",
    "mask = (precision >= 0.4) & (recall >= 0.9)\n",
    "valid = np.where(mask)[0]\n",
    "\n",
    "if len(valid) > 0:\n",
    "    idx = valid[np.argmax(recall[valid])]\n",
    "    print(\"✔ Found threshold with Precision≥0.4 & Recall≥0.9\")\n",
    "else:\n",
    "    # b) fallback: pick threshold that maximizes F1\n",
    "    f1_scores = 2 * precision * recall / (precision + recall + 1e-9)\n",
    "    idx = np.argmax(f1_scores)\n",
    "    print(\"⚠️  No threshold meets both goals; falling back to best‐F1 point\")\n",
    "\n",
    "matched_precision = precision[idx]\n",
    "matched_recall    = recall[idx]\n",
    "matched_threshold = thresholds[idx if idx < len(thresholds) else -1]\n",
    "\n",
    "print(f\"Threshold = {matched_threshold:.3f}\")\n",
    "print(f\"Precision = {matched_precision:.3f}\")\n",
    "print(f\"Recall    = {matched_recall:.3f}\")\n",
    "\n",
    "# Plot Precision–Recall curve \n",
    "fig_pr, ax_pr = plt.subplots(figsize=(8,6))\n",
    "ax_pr.plot(recall, precision, marker='.', label=f'XGB + SMOTE (AP={avg_prec:.2f})')\n",
    "ax_pr.scatter(\n",
    "    matched_recall, matched_precision,\n",
    "    s=100, color='red',\n",
    "    label=(f'Th={matched_threshold:.3f}\\n'\n",
    "           f'P={matched_precision:.2f}, R={matched_recall:.2f}')\n",
    ")\n",
    "ax_pr.set_xlabel('Recall')\n",
    "ax_pr.set_ylabel('Precision')\n",
    "ax_pr.set_title('Precision–Recall Curve')\n",
    "ax_pr.grid(True)\n",
    "ax_pr.legend()\n",
    "\n",
    "# Calibration & Brier score \n",
    "prob_true, prob_pred = calibration_curve(y_test, y_prob, n_bins=10, strategy='uniform')\n",
    "brier = brier_score_loss(y_test, y_prob)\n",
    "print(f\"Brier score: {brier:.4f}\")\n",
    "\n",
    "fig_cal, ax_cal = plt.subplots(figsize=(8,6))\n",
    "ax_cal.plot(prob_pred, prob_true, marker='o', label='Calibration')\n",
    "ax_cal.plot([0,1], [0,1], linestyle='--', label='Perfect')\n",
    "ax_cal.set_xlabel('Mean predicted prob')\n",
    "ax_cal.set_ylabel('Fraction of positives')\n",
    "ax_cal.set_title('Calibration Curve')\n",
    "ax_cal.grid(True)\n",
    "ax_cal.legend()\n",
    "\n",
    "#9) Feature importances \n",
    "feat_imp = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': best_clf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "fig_fi, ax_fi = plt.subplots(figsize=(8,6))\n",
    "feat_imp.head(15).plot.barh(x='feature', y='importance', legend=False, ax=ax_fi)\n",
    "ax_fi.invert_yaxis()\n",
    "ax_fi.set_title('Top 15 Feature Importances')\n",
    "ax_fi.set_xlabel('Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save files \n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "joblib.dump(best_clf,      \"models/bcsc_xgb_model.pkl\")\n",
    "joblib.dump(matched_threshold, \"models/threshold.pkl\")\n",
    "fig_pr.savefig(\"pr_curve.png\", dpi=300)\n",
    "fig_cal.savefig(\"calibration_curve.png\", dpi=300)\n",
    "fig_fi.savefig(\"feature_importance.png\", dpi=300)\n",
    "\n",
    "y_pred_label = (y_prob >= matched_threshold).astype(int)\n",
    "\n",
    "# Compute accuracy and confusion matrix\n",
    "acc = accuracy_score(y_test, y_pred_label)\n",
    "cm  = confusion_matrix(y_test, y_pred_label)\n",
    "print(f\"Overall accuracy at threshold {matched_threshold:.3f}: {acc:.3f}\")\n",
    "\n",
    "# Plot the confusion matrix\n",
    "fig_cm, ax_cm = plt.subplots(figsize=(6,6))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No Cancer','Cancer'])\n",
    "disp.plot(ax=ax_cm, cmap=plt.cm.Blues, values_format='d')\n",
    "ax_cm.set_title(f'Confusion Matrix (Acc={acc:.2f})')\n",
    "plt.tight_layout()\n",
    "fig_cm.savefig(\"confusion_matrix.png\", dpi=300)\n",
    "\n",
    "\n",
    "print(\"All files saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
